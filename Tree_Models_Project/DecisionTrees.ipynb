{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDrcOVDGnyDI",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## About iPython Notebooks ##\n",
    "\n",
    "iPython Notebooks are interactive coding environments embedded in a webpage. You will be using iPython notebooks in this class. Make sure you fill in any place that says `# BEGIN CODE HERE #END CODE HERE`. After writing your code, you can run the cell by either pressing \"SHIFT\"+\"ENTER\" or by clicking on \"Run\" (denoted by a play symbol). Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All). \n",
    "\n",
    " **What you need to remember:**\n",
    "\n",
    "- Run your cells using SHIFT+ENTER (or \"Run cell\")\n",
    "- Write code in the designated areas using Python 3 only\n",
    "- Do not modify the code outside of the designated areas\n",
    "- In some cases you will also need to explain the results. There will also be designated areas for that. \n",
    "\n",
    "Fill in your **NAME** and **AEM** below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JEJWwHpJnyDK",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NAME = \"Αλέξανδρος Τσίγγος\"\n",
    "AEM = \"3690\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRgauGbInyDM",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "_FF68cfznyDO",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce63642cafb413e7903d83d2f2cd3637",
     "grade": false,
     "grade_id": "cell-f62db6dce1ed3f2e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Assignment 2 - Decision Trees #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "zq29ctnanyDO",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "29d61ce286fdb8fd61c7f8e89a9e1339",
     "grade": false,
     "grade_id": "cell-dce2e73cee9a5017",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Welcome to your second assignment. This exercise gives you an introduction to [scikit-learn](https://scikit-learn.org/stable/). A simple but efficient machine learning library in Python. It also gives you a wide understanding on how decision trees work. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "mb4Wf4IdnyDP",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "50a108d2f1e1a1ee2fde80743c0543fe",
     "grade": false,
     "grade_id": "cell-83ca2b0456fb85db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After this assignment you will:\n",
    "- Be able to use the scikit-learn library and train your own model from scratch.\n",
    "- Be able to train and understand decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "sLqpxgvbnyDQ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "396c39a0797964c378ebb90cf18a29de",
     "grade": false,
     "grade_id": "cell-2cef6d48eea484d8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Always run this cell\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "# USE THIS RANDOM VARIABLE TO PRODUCE THE SAME RESULTS\n",
    "RANDOM_VARIABLE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLqRTrLTnyDR",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Scikit-Learn and Decision Trees ##\n",
    "\n",
    "You are going to use the scikit-learn library to train a model for detecting breast cancer using the [Breast cancer wisconsin (diagnostic) dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer) (+ [Additional information](https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset)) by training a model using [decision trees](https://scikit-learn.org/stable/modules/tree.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7d5K-BdnyDS",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**1.1** Load the breast cancer dataset using the scikit learn library and split the dataset into train and test set using the appropriate function. Use 33% of the dataset as the test set. Define as X the attributes and as y the target values. Do not forget to set the random_state parameter as the *RANDOM_VARIABLE* defined above. Use this variable for all the random_state parameters in this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "id": "NfF54h6anyDS",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b873328ea05f6ef9c08827168c7b835",
     "grade": false,
     "grade_id": "cell-1f0c2f3918333cf6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "X, y = load_breast_cancer().data, load_breast_cancer().target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=RANDOM_VARIABLE)\n",
    "\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "FiOtzHkpnyDT",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3603b2ba8916ffdad9e9c53f31546b4c",
     "grade": true,
     "grade_id": "cell-3f43c895ceaf57a9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train set:381\n",
      "Size of test set:188\n",
      "Unique classes:2\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of train set:{}\".format(len(y_train)))\n",
    "print(\"Size of test set:{}\".format(len(y_test)))\n",
    "print(\"Unique classes:{}\".format(len(set(y_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "JuW_lKVFnyDU",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "62285a7bd3ab59718b89f7e09de0fea4",
     "grade": false,
     "grade_id": "cell-1ce621a108e76a15",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Expected output**:  \n",
    "\n",
    "```\n",
    "Size of train set:381  \n",
    "Size of test set:188  \n",
    "Unique classes:2\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUB8sl0NnyDV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**1.2** Train two DecisionTree classifiers and report the F1 score. Use the information gain for the one classifier and the Gini impurity for the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "id": "nPQFaOhLnyDW",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17197b62614427a979fcbab7ed2734dd",
     "grade": false,
     "grade_id": "cell-a7fa1d29509eb2a1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "classifier_gini = DecisionTreeClassifier(criterion=\"gini\", random_state=RANDOM_VARIABLE)\n",
    "classifier_igain = DecisionTreeClassifier(criterion=\"entropy\",random_state=RANDOM_VARIABLE)\n",
    "\n",
    "classifier_gini.fit(X_train,y_train)\n",
    "classifier_igain.fit(X_train,y_train)\n",
    "\n",
    "prediction_gini = classifier_gini.predict(X_test)\n",
    "prediction_igain = classifier_igain.predict(X_test)\n",
    "\n",
    "f_measure_gini = f1_score(y_pred=prediction_gini, y_true=y_test)\n",
    "f_measure_igain = f1_score(y_pred=prediction_igain, y_true=y_test)\n",
    "\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "qToIpGtnnyDX",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d9aab4355c27c346f7e6548f233e758",
     "grade": true,
     "grade_id": "cell-09657a82bf4028c4",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "971906be-59d1-412b-8cbd-c48f36fb104b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Measure Gini: 0.9372384937238494\n",
      "F-Measure Information Gain: 0.9596774193548386\n"
     ]
    }
   ],
   "source": [
    "print(\"F-Measure Gini: {}\".format(f_measure_gini))\n",
    "print(\"F-Measure Information Gain: {}\".format(f_measure_igain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "hn9nblQ5nyDY",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f3facbbef0dd8f25ad12bfec7c174818",
     "grade": false,
     "grade_id": "cell-b0d8630f3b764cf3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Expected output**:  \n",
    "\n",
    "```\n",
    "F-Measure Gini: 0.9372384937238494\n",
    "F-Measure Information Gain: 0.9596774193548386\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "31Iyi9SJnyDZ",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f2532168d16e8c9bffba3d7d8e1efce7",
     "grade": false,
     "grade_id": "cell-591ba122016b6db5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**1.3** Find the maximum depth reached by the tree that used the Gini impurity. Train multiple classifiers by modifying the max_depth within the range from 1 to maximum depth and save the f1 scores to the corresponding list of the *fscores* dictionary (one list for training set and one for test set). Before appending the scores to the corresponding list, multiply them by 100, and round the values to 2 decimals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "id": "U7gSfRu_nyDa",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "54cf257e90a3cb5877db81297bedd45c",
     "grade": false,
     "grade_id": "cell-31c58b6161a3907d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "depth = classifier_gini.get_depth()\n",
    "fscores = {}\n",
    "fscores['train'] = []\n",
    "fscores['test'] = []\n",
    "\n",
    "for i in range(1,depth+1,1):\n",
    "    classifier = DecisionTreeClassifier(criterion=\"gini\", random_state=RANDOM_VARIABLE, max_depth=i)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    prediction_train = classifier.predict(X_train)\n",
    "    prediction_test = classifier.predict(X_test)\n",
    "    fscores['train'].append(round(f1_score(y_pred=prediction_train,y_true=y_train)*100,2))\n",
    "    fscores['test'].append(round(f1_score(y_pred=prediction_test,y_true=y_test)*100,2))\n",
    "\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "2395Por-nyDa",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70a249937f2f690c6ce855debaed204c",
     "grade": true,
     "grade_id": "cell-0c300109423f53b9",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "02203fa9-4930-428f-d796-da5dbfaa41a5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fscores Train: [94.24, 95.46, 97.65, 99.15, 99.37, 99.58, 100.0]\n",
      "Fscores Test:  [91.14, 93.97, 96.64, 94.12, 95.4, 95.04, 93.72]\n"
     ]
    }
   ],
   "source": [
    "print(\"Fscores Train: {}\".format(fscores['train']))\n",
    "print(\"Fscores Test:  {}\".format(fscores['test']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "f37yzYcbnyDb",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3db472d2b9db7a42cc012cd96fdeb499",
     "grade": false,
     "grade_id": "cell-75789627f20d2c94",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Expected output**:  \n",
    "```\n",
    "Fscores Train: [94.24, 95.46, 97.65, 99.15, 99.37, 99.58, 100.0]\n",
    "Fscores Test:  [91.14, 93.97, 96.64, 94.12, 95.4, 95.04, 93.72]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "4stz0V9knyDd",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bca7d4c160c767d27a09b4620d27d56e",
     "grade": false,
     "grade_id": "cell-5906e6d5efa70282",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**1.4** Compare the results from the train set with the results from the test set. What do you notice? How are you going to choose the max_depth of your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "kwtDaX3JnyDe",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "424ac10e4e22ca9e32207deee3bf0f57",
     "grade": true,
     "grade_id": "cell-c9c6ea0e40d98b83",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<ul>\n",
    "    <li>Αρχικά παρατηρούμε ότι το f1_score στο Train set είναι πιο υψηλό σε σχέση με αυτό του Test set σε κάθε ένα από τα διαφορετικά depths, το οποίο είναι και λογικό αφού με το Train Set εκπαιδεύτηκε το μοντέλο.</li>\n",
    "    <li>Στη συνέχεια, παρατηρούμε στο f1_score του Train set πως όσο αυξάνουμε τη hyperparameter max_depth, τόσο πιο πολύ βελτιώνεται και το f1_score ώσπου φτάνουμε μέχρι και το 100 (δηλαδή το μοντέλο μας κάνει τέλειο classification στα examples που του δώσαμε) με αποτέλεσμα να έχει γίνει overfit. Το ότι έχει γίνει overfit στις πιο μεγάλες τιμές του max_depth επιβεβαιώνεται και από το γεγονός ότι το f1_score του Test Set ενώ μέχρι ένα σημείο αυξάνεται μετά αρχίζει και μειώνεται (96.64 --> 94.12).</li>\n",
    "    <li>Συνεπώς, θα βλέπαμε μέχρι ποιο βάθος αυξάνεται το f1_score και στο Train αλλά και στο Test Set και θα επιλέγαμε αυτό ως max_depth. Στο παράδειγμά μας, θα επιλέγαμε ως max_depth = 3, καθώς μετά από αυτό το βάθος το f1_score μειώνεται στο Test Set, το οποίο είναι ένδειξη για την ύπαρξη overfit.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "PIw1fVFenyDe",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "217666fcc2e383d6f2c1904c9d6a71be",
     "grade": false,
     "grade_id": "cell-9ef42e6c90ea2ffe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.0 Pipelines ##\n",
    "\n",
    "**2.1** In this part of the exercise you are going to build a pipeline from scratch for a classification problem. Load the **income.csv** file and train a DecisionTree model that will predict the *income* variable. This dataset is a modification of the original Adult Income dataset found [here](http://archive.ics.uci.edu/ml/datasets/Adult). Report the f1-score and accuracy score of the test set found in **income_test.csv**. Your pipeline should be able to handle missing values and categorical features (scikit-learn's decision trees do not handle categorical values). You can preprocess the dataset as you like in order to achieve higher scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7jJW-avitO9E",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# BEGIN CODE HERE\n",
    "data = pd.read_csv('income.csv')\n",
    "train_set = data[['age','workclass','fnlwgt','education','education_num','marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week']]\n",
    "y_train = data['income'].map({ \"<=50K\": 0, \">50K\": 1 })\n",
    "# any other code you need\n",
    "\n",
    "test_data = pd.read_csv('income_test.csv')\n",
    "test_set = test_data[['age','workclass','fnlwgt','education','education_num','marital-status','occupation','relationship','race','sex','capital-gain','capital-loss','hours-per-week']]\n",
    "y_test = test_data['income'].map({ \"<=50K\": 0, \">50K\": 1 })\n",
    "# any other code you need\n",
    "# End CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "akVGpGHDuav4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**2.2** Create and test your pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pv6z98huuZ6M",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Your pipeline\n",
    "numeric_features = [\"age\", \"fnlwgt\",\"education_num\",\"capital-gain\", \"capital-loss\",\"hours-per-week\"]\n",
    "numeric_transformer = Pipeline(steps=[(\"imputer\", SimpleImputer(strategy=\"median\"))])\n",
    "categorical_features = [\"workclass\", \"education\",\"marital-status\",\"occupation\",\"relationship\",\"race\",\"sex\"]\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"one_hot_cat\", categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "clf = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", DecisionTreeClassifier(random_state=RANDOM_VARIABLE))])\n",
    "clf.fit(train_set,y_train)\n",
    "y_predict =  clf.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3uaArYmQvKcf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score Accuracy: 0.807\n",
      "Model score F1 Weighted: 0.808\n"
     ]
    }
   ],
   "source": [
    "print(\"Model score Accuracy: %.3f\" % accuracy_score(y_test, y_predict))\n",
    "print(\"Model score F1 Weighted: %.3f\" % f1_score(y_test, y_predict,average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zz_MWnYY2r3-",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**2.3** Perform a gooood grid search to find the best parameters for your pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "RNECyUFtnyDf",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "152ab2dd6861b198b879a78ebadc4ee4",
     "grade": true,
     "grade_id": "cell-dd950ab2eb40d8a4",
     "locked": false,
     "points": 45,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "7955851a-cad6-4132-bd66-587543300978",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:\n",
      "{'classifier__criterion': 'gini', 'classifier__max_depth': 10, 'classifier__max_features': None, 'classifier__min_samples_leaf': 10, 'preprocessor__num__imputer__strategy': 'mean'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_13820\\955853934.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[0mgrid_search\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mGridSearchCV\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparam_grid\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcv\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m \u001B[0mgrid_search\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_set\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m \u001B[0my_predict\u001B[0m \u001B[1;33m=\u001B[0m  \u001B[0mgrid_search\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_set\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     70\u001B[0m                           FutureWarning)\n\u001B[0;32m     71\u001B[0m         \u001B[0mkwargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m{\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0marg\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 72\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     73\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0minner_f\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     74\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    734\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mresults\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    735\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 736\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_run_search\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mevaluate_candidates\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    737\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    738\u001B[0m         \u001B[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36m_run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1186\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_run_search\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevaluate_candidates\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1187\u001B[0m         \u001B[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1188\u001B[1;33m         \u001B[0mevaluate_candidates\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mParameterGrid\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparam_grid\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1189\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\MLenv\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36mevaluate_candidates\u001B[1;34m(candidate_params)\u001B[0m\n\u001B[0;32m    713\u001B[0m                                \u001B[1;32mfor\u001B[0m \u001B[0mparameters\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mtrain\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    714\u001B[0m                                in product(candidate_params,\n\u001B[1;32m--> 715\u001B[1;33m                                           cv.split(X, y, groups)))\n\u001B[0m\u001B[0;32m    716\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    717\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m<\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\MLenv\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1059\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1060\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mretrieval_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1061\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mretrieve\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1062\u001B[0m             \u001B[1;31m# Make sure that we get a last message telling us we are done\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1063\u001B[0m             \u001B[0melapsed_time\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_start_time\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\MLenv\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36mretrieve\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    938\u001B[0m             \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    939\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'supports_timeout'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 940\u001B[1;33m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_output\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mjob\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    941\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    942\u001B[0m                     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_output\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mjob\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\MLenv\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36mwrap_future_result\u001B[1;34m(future, timeout)\u001B[0m\n\u001B[0;32m    540\u001B[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001B[0;32m    541\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 542\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfuture\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    543\u001B[0m         \u001B[1;32mexcept\u001B[0m \u001B[0mCfTimeoutError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    544\u001B[0m             \u001B[1;32mraise\u001B[0m \u001B[0mTimeoutError\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\MLenv\\lib\\concurrent\\futures\\_base.py\u001B[0m in \u001B[0;36mresult\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    428\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__get_result\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    429\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 430\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_condition\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    431\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    432\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_state\u001B[0m \u001B[1;32min\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mCANCELLED\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mCANCELLED_AND_NOTIFIED\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\MLenv\\lib\\threading.py\u001B[0m in \u001B[0;36mwait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    294\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m    \u001B[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    295\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mtimeout\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 296\u001B[1;33m                 \u001B[0mwaiter\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0macquire\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    297\u001B[0m                 \u001B[0mgotit\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    298\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"preprocessor__num__imputer__strategy\": [\"mean\", \"median\"],\n",
    "    \"classifier__max_depth\": [2, 5, 10],\n",
    "    \"classifier__criterion\": [\"gini\",\"entropy\"],\n",
    "    \"classifier__max_features\": [3, 7, 9, 11, None],\n",
    "    \"classifier__min_samples_leaf\": [1,10,20,50],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(train_set,y_train)\n",
    "y_predict =  grid_search.predict(test_set)\n",
    "\n",
    "print(\"Best params:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OhE0haFuw57D",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Model score Accuracy: %.3f\" % accuracy_score(y_test,y_predict))\n",
    "print(\"Model score F1 Weighted: %.3f\" % f1_score(y_test,y_predict,average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "f_lIQ1-wnyDg",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ee9d4c2635307395bdef2efb941106ae",
     "grade": false,
     "grade_id": "cell-2c3327274958bbad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**2.4** Describe the process you followed to achieve the results above. Your description should include, but is not limited to the following \n",
    "- How do you handle missing values and why\n",
    "- How do you handle categorical variables and why\n",
    "- Any further preprocessing steps\n",
    "- How do you evaluate your model and how did you choose its parameters \n",
    "- Report any additional results and comments on your approach.\n",
    "\n",
    "You should achieve at least 85% accuracy score and 84% f1 score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "76FF0gYVnyDh",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1aaf3ddda45b52c2e43089b082d030f1",
     "grade": true,
     "grade_id": "cell-80274fd09b80518c",
     "locked": false,
     "points": 20,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<ul>\n",
    "    <li>How do you handle missing values and why</li>\n",
    "        <ul>\n",
    "            <li>Το data set μας έχει missing values στο feature \"workclass\"(categorical feature) και στο feature \"occupation\"(categorical feature). Θα μπορούσαμε να διαγράψουμε τα examples που έχουν missing values, ωστόσο για να μην χάσουμε πληροφορία από το Data Set μας, προτιμήθηκε να γίνει imputation των missing values(Στα numerical features ακολουθήσαμε ως στρατηγική το median ενώ σε categorical features χρησιμοποιήσαμε το most frequent, που έχει νόημα όταν διαχειριζόμαστε categorical features)</li>\n",
    "        </ul>\n",
    "    <li>How do you handle categorical variables and why</li>\n",
    "        <ul>\n",
    "            <li>Στα categorical variables αρχικά κάναμε imputation στα missing values για να τα εξαλείψουμε από το Data Set μας και έπειτα χρησιμοποιήσαμε τον one hot encoder προκείμενου να κάνουμε encode τα categorical features σε numerical features μιας και ο αλγόριθμος CART δέχεται μόνο numerical features./li>\n",
    "        </ul>\n",
    "    <li>Any further preprocessing steps</li>\n",
    "        <ul><li>Δεν κάναμε κάτι παρπάνω πέρα από αυτά που ήδη αναφέραμε. Δεν έγινε κάποιο normalization/standardization γιατί είμαστε στην οικογένεια των Δενδρικών Μοντέλων</li></ul>\n",
    "    <li>How do you evaluate your model and how did you choose its parameters</li>\n",
    "        <ul>\n",
    "            <li>Το μοντέλο μας αξιολογείται με τις μετρικές Accuracy και f1 score(weighted), ενώ οι υπερ-παράμετροι του μοντέλου επιλέχθηκαν έπειτα από gridSearchCV (δοκιμάζονται όλοι οι συνδυασμοί των υπερ-παραμέτρων που έχουμε ορίσει στην μεταβλητή param_grid και επίλέγεται εκείνος ο συνδυασμός παραμέτρων που μας δίνει το πιο υψηλό performance)</li>\n",
    "        </ul>\n",
    "     <li>Report any additional results and comments on your approach.</li>\n",
    "        <ul><li>Το μοντέλο μας σημείωσε Accuracy: 0.857 και F1 Weighted: 0.850</li></ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "mNqPY_yanyDj",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8cef3f333ab449ed91b81ea96695e712",
     "grade": false,
     "grade_id": "cell-555d20216f9bbec2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3.0 Common Issues ## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USyDSnDCnyDk",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**3.0** Run the following code to define a DecisionTreeModel and load the **income** dataset only with the numerical variables. Then, answer the following questions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "G9M3JhlpnyDl",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae0f57b86252cc38b02cac3d05e08bbf",
     "grade": false,
     "grade_id": "cell-d7f58621bad12aad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score accuracy: 0.790\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "columns = ['age','fnlwgt','education_num','hours-per-week',\"capital-loss\",\"capital-gain\",\"income\"]\n",
    "data = pd.read_csv('income.csv',usecols=columns)\n",
    "data_test = pd.read_csv('income_test.csv',usecols=columns)\n",
    "# Convert target variable to 0 and 1\n",
    "data[\"income\"] = data[\"income\"].map({ \"<=50K\": 0, \">50K\": 1 })\n",
    "data_test[\"income\"] = data_test[\"income\"].map({ \"<=50K\": 0, \">50K\": 1 })\n",
    "# Create X and y\n",
    "X_train = data.drop([\"income\"],axis=1)\n",
    "y_train = data['income'].values\n",
    "X_test = data_test.drop([\"income\"],axis=1)\n",
    "y_test = data_test['income'].values\n",
    "# Classifier\n",
    "classifier = DecisionTreeClassifier(min_samples_leaf=4)\n",
    "classifier.fit(X_train,y_train)\n",
    "y_predict = classifier.predict(X_test) #προστέθηκε από εμένα, γιατί διαφορετικά στην επόμενη γραμμή θα είχαμε το y_predict από την άσκηση 2.3\n",
    "accuracy = accuracy_score(y_test,y_predict) #άλλαξα το όνομα της μεταβλητής από accuracy_score σε accuracy\n",
    "print(\"Model score accuracy: %.3f\" % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Yal5vVVInyDo",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c3981752b539236e99415ab6e2cbea1f",
     "grade": false,
     "grade_id": "cell-9b18d6c4e381a9f5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**3.1** Evaluate the classifier using at least three evaluation metrics except accuracy_score and f1 (weighted)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "deletable": false,
    "id": "4HaPGUuUnyDo",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "12b88026c150b617074a5c06fea36b73",
     "grade": true,
     "grade_id": "cell-905e7dceeb4172c3",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, average_precision_score, f1_score\n",
    "y_predict = classifier.predict(X_test)\n",
    "\n",
    "# BEGIN CODE HERE\n",
    "metric1 = f1_score(y_test,y_predict,average='macro')\n",
    "metric2 = balanced_accuracy_score(y_test,y_predict)\n",
    "metric3 = average_precision_score(y_test,y_predict)\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "H03BYlAC6B5u",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score Metric 1: 0.698\n",
      "Model score Metric 2: 0.687\n",
      "Model score Metric 3: 0.413\n"
     ]
    }
   ],
   "source": [
    "print(\"Model score Metric 1: %.3f\" % metric1)\n",
    "print(\"Model score Metric 2: %.3f\" % metric2)\n",
    "print(\"Model score Metric 3: %.3f\" % metric3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "YJxhaPxdnyDr",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "361d4753f3c8491a34ff55b6fa3a49b5",
     "grade": false,
     "grade_id": "cell-1f23f3e27600f019",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**3.2** Do you notice any problems with the classifier? If so, what can you do to change this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "PIEyNQJsnyDt",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "baff993106fd2b655fd47d05c75ea4ce",
     "grade": true,
     "grade_id": "cell-d60d7e6175d184e9",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Το πρόβλημα που παρατηρούμε στον classifier είναι το γεγονός πως έχουμε ορίσει μόνο μία υπέρ-παράμετρο(αυτή του min_samples_leaf) και άρα το decision tree δεν έχει κάποιον ιδιαίτερο περιορισμό στην εκπαίδευσή του. Επομένως, σε αυτήν την περίπτωση ελοχεύει ο κίνδυνος του overfit. Για να αντιμετωπίσουμε αυτό θα κάνουμε ένα stratified grid search για να μπορέσουμε να βρούμε εκείνο τον συνδυασμό των υπέρ-παραμέτρων που μας οδηγούν σε καλύτερο performance του μοντέλου."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "WCN7E_ctnyDu",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "747645b33cb4f5c14796504fac6bf3ce",
     "grade": false,
     "grade_id": "cell-89715acd6c51b332",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**3.3** Implement your solution using the cells below. Report your results and the process you followed. You are reccommended to use stratification and grid search. You should only have to increase a little bit the metrics you calculated above, and also reach an accuracy score higher than 82%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "deletable": false,
    "id": "g9Wzx0bknyDv",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ccd1d12620f1a3e1c7b026b862056546",
     "grade": true,
     "grade_id": "cell-f44811f1e99ee41e",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# BEGIN CODE HERE\n",
    "final_score = \"\"\n",
    "stratification = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=RANDOM_VARIABLE)\n",
    "param_grid = [\n",
    "    {'criterion': [\"gini\",\"entropy\"],\n",
    "     'max_features': [2, 4, 5, None],\n",
    "     'min_samples_leaf': [1,10,20,50],\n",
    "     'max_depth': [2,5,10]}\n",
    "]\n",
    "grid_search = GridSearchCV(classifier, param_grid, cv=stratification,\n",
    "                           scoring='accuracy', return_train_score=True)\n",
    "grid_search.fit(X_train,y_train)\n",
    "y_predict = grid_search.predict(X_test)\n",
    "accuracy = accuracy_score(y_test,y_predict)\n",
    "metric1 = f1_score(y_test,y_predict,average='macro')\n",
    "metric2 = balanced_accuracy_score(y_test,y_predict)\n",
    "metric3 = average_precision_score(y_test,y_predict)\n",
    "#END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "HoDBPL6n6LLI",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score accuracy: 0.824\n",
      "Model score Metric 1: 0.717\n",
      "Model score Metric 2: 0.689\n",
      "Model score Metric 3: 0.462\n"
     ]
    }
   ],
   "source": [
    "print(\"Model score accuracy: %.3f\" % accuracy) #άλλαξα το όνομα της μεταβλητής από accuracy_score σε accuracy\n",
    "print(\"Model score Metric 1: %.3f\" % metric1)\n",
    "print(\"Model score Metric 2: %.3f\" % metric2)\n",
    "print(\"Model score Metric 3: %.3f\" % metric3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "id": "ZyG7hhbFnyDx",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b26041c1723d2858ad0833f8985801db",
     "grade": true,
     "grade_id": "cell-c99ca88f33f3717c",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Παραπάνω, εφαρμόσαμε ένα stratified grid search δοκιμάζοντας 4 παραμέτρους (criterion,max_features,min_samples_leaf,max_depth) και εκπαιδεύσαμε το μοντέλο μας με τον συνδυασμό των υπέρ-παραμέτρων που μας επέστρεψε το grid search. Αποτέλεσμα αυτού ήταν μια μικρή αύξηση στα metrics 1,2 και 3 και το γεγονός ότι πετύχαμε accuracy score ίσο με 0.824."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DecisionTrees.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}